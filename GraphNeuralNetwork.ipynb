{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7de17d-6170-4533-8b78-71605ad326eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install torch#==2.2\n",
    "# !pip install torch_geometric#==2.4.0\n",
    "# !pip install seaborn#==0.12.2\n",
    "# !pip install networkx#==2.8.5\n",
    "# !pip install scikit-learn#==1.3.2\n",
    "# !pip install matplotlib#==3.5.2\n",
    "# !pip install pandas#==1.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a4b69-2a21-40f3-b4ba-ea304319d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import f1_score\n",
    "from copy import deepcopy  \n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0463b7-f62f-4cb9-af7a-b0deb1a4aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(data, labels):\n",
    "    tsne = TSNE(n_components=2, init='pca', random_state=7)\n",
    "    tsne_res = tsne.fit_transform(data)\n",
    "    v = pd.DataFrame(data,columns=[str(i) for i in range(data.shape[1])])\n",
    "    v['color'] = labels\n",
    "    v['label'] = v['color'].apply(lambda i: str(i))\n",
    "    v[\"dim1\"] = tsne_res[:,0]\n",
    "    v[\"dim2\"] = tsne_res[:,1]\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=\"dim1\", y=\"dim2\",\n",
    "        hue=\"color\",\n",
    "        palette=sns.color_palette([\"#52D1DC\", \"#8D0004\", \"#845218\",\"#563EAA\", \"#E44658\", \"#63C100\", \"#FF7800\"]),\n",
    "        legend=False,\n",
    "        data=v,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1fcc68-aa83-4ee8-b5b0-22209fa658b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph(G, color):\n",
    "    plt.figure(figsize=(75,75))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, pos=nx.arf_layout(G), with_labels=False,\n",
    "                     node_color=color, cmap=\"rainbow\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f5cc1-8082-4459-adb2-4c33c432dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import EllipticBitcoinDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e9676-ee24-4a7f-a1cf-cb5fbe605672",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EllipticBitcoinDataset(root='data/EllipticBitcoinDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb623eae-2577-4039-89dc-1f7149105553",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run elliptic_data_visual_schema.py\n",
    "%run model_trainer_compare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510693c-a69a-4b29-8002-c3ada68e858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_elliptic_dataset_overview(dataset[0], dataset, save_path='elliptic_overview.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16929b9-2a77-4b4b-9ec0-30b227df1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "pd.Series(data.y.numpy()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc998e43-2467-4ffd-b482-7b008744d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.train_mask.sum() + data.test_mask.sum())\n",
    "print(data.y[data.train_mask].sum() + data.y[data.test_mask].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad6d129-07c3-4928-be57-625de5ff0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure `train_mask` exists and is a Boolean tensor\n",
    "train_mask = data.train_mask.bool()\n",
    "\n",
    "# Determine the number of training nodes\n",
    "train_indices = train_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "# Shuffle the training indices for random splitting\n",
    "train_indices = train_indices[torch.randperm(train_indices.size(0))]\n",
    "\n",
    "# Define the size of the validation set (e.g., 20% of the training nodes)\n",
    "val_size = int(0.2 * len(train_indices))\n",
    "\n",
    "# Split the training indices into validation and new training sets\n",
    "val_indices = train_indices[:val_size]\n",
    "new_train_indices = train_indices[val_size:]\n",
    "\n",
    "# Create new masks for training and validation\n",
    "new_train_mask = torch.zeros_like(train_mask)\n",
    "new_val_mask = torch.zeros_like(train_mask)\n",
    "\n",
    "new_train_mask[new_train_indices] = True\n",
    "new_val_mask[val_indices] = True\n",
    "\n",
    "# Update the data object with the new masks\n",
    "data.train_mask = new_train_mask\n",
    "data.val_mask = new_val_mask\n",
    "\n",
    "# Verify the sizes of the new masks\n",
    "print(\"Training nodes:\", new_train_mask.sum().item())\n",
    "print(\"Validation nodes:\", new_val_mask.sum().item())\n",
    "print(\"Testing nodes:\", data.test_mask.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6a9c3-3136-45ba-9fc0-ca1a9ae64361",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.subgraph(subset=val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfaa8af-7f0b-4c34-9874-18f098cbb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph(G, color):\n",
    "    plt.figure(figsize=(60,60))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, pos=nx.random_layout(G), with_labels=False,\n",
    "                     node_color=color, cmap=\"winter_r\", arrows=True)\n",
    "    plt.savefig('foo.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667dd69e-c16a-48b1-a603-c02804f41c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(data.subgraph(subset=val_indices))\n",
    "visualize_graph(G, color=data.subgraph(subset=val_indices).y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9853806-83af-46e1-8ca6-8615a4a360a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure train_mask exists and is Boolean\n",
    "train_mask = data.train_mask.bool()\n",
    "train_indices = train_mask.nonzero(as_tuple=True)[0]\n",
    "train_indices = train_indices[torch.randperm(train_indices.size(0))]\n",
    "\n",
    "# Define validation size (20%)\n",
    "val_size = int(0.2 * len(train_indices))\n",
    "val_indices = train_indices[:val_size]\n",
    "new_train_indices = train_indices[val_size:]\n",
    "\n",
    "# Create new masks\n",
    "new_train_mask = torch.zeros_like(train_mask)\n",
    "new_val_mask = torch.zeros_like(train_mask)\n",
    "new_train_mask[new_train_indices] = True\n",
    "new_val_mask[val_indices] = True\n",
    "\n",
    "# Update data object with new masks\n",
    "data.train_mask = new_train_mask\n",
    "data.val_mask = new_val_mask  # ← This creates the val_mask attribute!\n",
    "\n",
    "# Verify sizes\n",
    "print(f\"Training nodes:   {new_train_mask.sum().item():,}\")\n",
    "print(f\"Validation nodes: {new_val_mask.sum().item():,}\")\n",
    "print(f\"Testing nodes:    {data.test_mask.sum().item():,}\")\n",
    "print(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa18ab-687b-4bda-9dc1-d2c0fdf59b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_CHANNELS = 8\n",
    "NUM_EPOCHS = 1000\n",
    "LR = 0.01\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_EVERY = 100\n",
    "\n",
    "# Initialize comparison\n",
    "comparison = ModelComparison()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cc9a39-03b7-43d6-8fc0-56cb477d321e",
   "metadata": {},
   "source": [
    "# 1) Multi-Layer Perceptron (MLP)\n",
    "\n",
    "**Setup.** For node $i$ with feature vector $\\mathbf{x}_i \\in \\mathbb{R}^{165}$.\n",
    "\n",
    "**Model.**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{h}_1 &= \\sigma\\!\\left(\\mathbf{W}_1 \\mathbf{x}_i + \\mathbf{b}_1\\right), \\\\\n",
    "\\mathbf{z}_i &= \\mathbf{W}_2 \\mathbf{h}_1 + \\mathbf{b}_2, \\\\\n",
    "\\hat{\\mathbf{y}}_i &= \\mathrm{softmax}(\\mathbf{z}_i) \\in \\Delta^{1}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Loss (binary cross-entropy).**\n",
    "$$\n",
    "\\mathcal{L} \\;=\\; -\\sum_{i}\\sum_{c\\in\\{0,1\\}} y_{ic}\\,\\log \\hat{y}_{ic}.\n",
    "$$\n",
    "\n",
    "**Notes.** $\\sigma$ typically ReLU. No graph context; nodes are treated independently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2194fe0-fc36-4c27-b15c-2581e7736141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"Multi-Layer Perceptron (baseline model).\"\"\"\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, seed=20251120):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.lin1 = Linear(num_features, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index=None):  # edge_index optional for compatibility\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Train MLP\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING MLP MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mlp_model = MLP(\n",
    "    num_features=dataset.num_features,\n",
    "    hidden_channels=HIDDEN_CHANNELS,\n",
    "    num_classes=dataset.num_classes\n",
    ")\n",
    "\n",
    "      \n",
    "# Untrained model for baseline\n",
    "untrained_model = deepcopy(MLP(dataset.num_features, 8, dataset.num_classes))\n",
    "untrained_model.load_state_dict(mlp_model.state_dict())\n",
    "\n",
    "mlp_trainer = ModelTrainer(\n",
    "    model=mlp_model,\n",
    "    data=data,\n",
    "    model_name=\"MLP\",\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "mlp_trainer.train(num_epochs=NUM_EPOCHS, print_every=PRINT_EVERY)\n",
    "mlp_trainer.test()\n",
    "mlp_trainer.plot_learning_curves()\n",
    "comparison.add_model(\"MLP\", mlp_trainer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c5d1ca-f2c1-4715-8070-f2b904985067",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "    # Visualize trained model predictions\n",
    "    mlp_trainer.visualize_predictions_tsne(data.test_mask, \"Test\")\n",
    "    \n",
    "    # Compare before/after training\n",
    "    mlp_trainer.visualize_before_after(data.test_mask, untrained_model, \"Test\")\n",
    "    \n",
    "    # Detailed error analysis\n",
    "    mlp_trainer.analyze_errors(data.test_mask, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45516b65-b324-4699-babd-3dce5b8c6b60",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965b21b-e758-4a39-910e-b335e8ed07e4",
   "metadata": {},
   "source": [
    "# 2) Graph Convolutional Network (GCN)\n",
    "\n",
    "**Graph definition**  \n",
    "Let $G=(V,E)$ have adjacency $\\mathbf{A}$ and degree $\\mathbf{D}$.  \n",
    "Add self-loops: $\\tilde{\\mathbf{A}}=\\mathbf{A}+\\mathbf{I}$,  \n",
    "$\\tilde{\\mathbf{D}}_{ii}=\\sum_j \\tilde{\\mathbf{A}}_{ij}$.\n",
    "\n",
    "**Layer propagation**\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathbf{H}^{(\\ell+1)} = \n",
    "\\sigma\\!\\left(\n",
    "\\tilde{\\mathbf{D}}^{-\\frac{1}{2}}\n",
    "\\tilde{\\mathbf{A}}\n",
    "\\tilde{\\mathbf{D}}^{-\\frac{1}{2}}\n",
    "\\mathbf{H}^{(\\ell)}\n",
    "\\mathbf{W}^{(\\ell)}\n",
    "\\right)\n",
    "}\n",
    "\\quad\\text{with}\\quad\n",
    "\\mathbf{H}^{(0)}=\\mathbf{X}.\n",
    "$$\n",
    "\n",
    "**Output layer (logits)**\n",
    "$$\n",
    "\\mathbf{Z} =\n",
    "\\tilde{\\mathbf{D}}^{-\\frac{1}{2}}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-\\frac{1}{2}}\n",
    "\\mathbf{H}^{(L-1)}\\mathbf{W}^{(L-1)}.\n",
    "$$\n",
    "\n",
    "**Intuition.** Normalized neighborhood averaging (isotropic).  \n",
    "Acts as a low-pass filter on the graph Laplacian.  \n",
    "After $L$ layers, each node aggregates information from its $L$-hop neighborhood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfeaeff-3ba3-4ae7-9c3f-f4faff2786b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"Graph Convolutional Network.\"\"\"\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, seed = 20251120):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "# ============================================================\n",
    "# Train GCN\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING GCN MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "gcn_model = GCN(\n",
    "    num_features=dataset.num_features,\n",
    "    hidden_channels=HIDDEN_CHANNELS,\n",
    "    num_classes=dataset.num_classes\n",
    ")\n",
    "\n",
    "       \n",
    "# Untrained model for baseline\n",
    "untrained_model = deepcopy(GCN(dataset.num_features, 8, dataset.num_classes))\n",
    "untrained_model.load_state_dict(gcn_model.state_dict())\n",
    "\n",
    "\n",
    "gcn_trainer = ModelTrainer(\n",
    "    model=gcn_model,\n",
    "    data=data,\n",
    "    model_name=\"GCN\",\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "gcn_trainer.train(num_epochs=NUM_EPOCHS, print_every=PRINT_EVERY)\n",
    "gcn_trainer.test()\n",
    "gcn_trainer.plot_learning_curves()\n",
    "comparison.add_model(\"GCN\", gcn_trainer)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91466fa-2a98-4bb1-9b76-ececab58e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize trained model predictions\n",
    "gcn_trainer.visualize_predictions_tsne(data.test_mask, \"Test\")\n",
    "\n",
    "# Compare before/after training\n",
    "gcn_trainer.visualize_before_after(data.test_mask, untrained_model, \"Test\")\n",
    "\n",
    "# Detailed error analysis\n",
    "gcn_trainer.analyze_errors(data.test_mask, \"Test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc52a8-c7b3-4375-99b6-fcee2d3d3acd",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4dc21-d435-4a64-be10-2dc442df3964",
   "metadata": {},
   "source": [
    "# 3) Graph Attention Network (GAT)\n",
    "\n",
    "**Concept.** Replace uniform neighbor averaging with learned, anisotropic attention weights.\n",
    "\n",
    "**Per-layer computations (single head)**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{h}_i &= \\mathbf{W}\\mathbf{x}_i, \\\\[4pt]\n",
    "e_{ij} &= \\mathrm{LeakyReLU}\\!\\left(\\mathbf{a}^{\\top}[\\mathbf{h}_i \\Vert \\mathbf{h}_j]\\right), \\quad j\\in\\mathcal{N}(i), \\\\[4pt]\n",
    "\\alpha_{ij} &= \\frac{\\exp(e_{ij})}{\\sum_{k\\in\\mathcal{N}(i)} \\exp(e_{ik})}, \\\\[6pt]\n",
    "\\mathbf{h}_i' &= \\sigma\\!\\left(\\sum_{j\\in\\mathcal{N}(i)} \\alpha_{ij}\\,\\mathbf{h}_j\\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Multi-head attention**\n",
    "$$\n",
    "\\mathbf{h}_i' =\n",
    "\\big\\Vert_{k=1}^{K}\n",
    "\\sigma\\!\\left(\\sum_{j\\in\\mathcal{N}(i)} \\alpha_{ij}^{(k)}\\,\\mathbf{h}_j^{(k)}\\right)\n",
    "\\quad\\text{or}\\quad\n",
    "\\frac{1}{K}\\sum_{k=1}^{K}\n",
    "\\sigma\\!\\left(\\sum_{j} \\alpha_{ij}^{(k)}\\,\\mathbf{h}_j^{(k)}\\right).\n",
    "$$\n",
    "\n",
    "**Intuition.** Attention coefficients $\\alpha_{ij}$ emphasize informative neighbors and suppress noisy ones, allowing data-dependent message passing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e581652-55e8-4849-9cff-1ea66ca16da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    \"\"\"Graph Attention Network.\"\"\"\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, heads=4, seed = 20251120):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.conv1 = GATConv(num_features, hidden_channels, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, num_classes, heads=1)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Train GAT\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING GAT MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "gat_model = GAT(\n",
    "    num_features=dataset.num_features,\n",
    "    hidden_channels=HIDDEN_CHANNELS,\n",
    "    num_classes=dataset.num_classes,\n",
    "    heads=4\n",
    ")\n",
    "\n",
    "# Untrained model for baseline\n",
    "ungat_model = deepcopy(GAT(dataset.num_features, 8, dataset.num_classes))\n",
    "ungat_model.load_state_dict(gat_model.state_dict())\n",
    "\n",
    "\n",
    "gat_trainer = ModelTrainer(\n",
    "    model=gat_model,\n",
    "    data=data,\n",
    "    model_name=\"GAT\",\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "gat_trainer.train(num_epochs=NUM_EPOCHS, print_every=PRINT_EVERY)\n",
    "gat_trainer.test()\n",
    "gat_trainer.plot_learning_curves()\n",
    "comparison.add_model(\"GAT\", gat_trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948470be-2d48-428d-a5fb-fa556d006d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize trained model predictions\n",
    "gat_trainer.visualize_predictions_tsne(data.test_mask, \"Test\")\n",
    "\n",
    "# Compare before/after training\n",
    "gat_trainer.visualize_before_after(data.test_mask, ungat_model, \"Test\")\n",
    "\n",
    "# Detailed error analysis\n",
    "gat_trainer.analyze_errors(data.test_mask, \"Test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6080c00-8740-4466-8a21-c223e9292529",
   "metadata": {},
   "source": [
    "# 4) Comparative Summary\n",
    "\n",
    "| Model | Aggregation | Key operator | Information scope | Behavior |\n",
    "|:------|:-------------|:--------------|:------------------|:----------|\n",
    "| **MLP** | None (independent nodes) | Linear layers + nonlinearity | Self only | Ignores graph topology |\n",
    "| **GCN** | Normalized uniform average | $\\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$ | $L$-hop neighbors | Smooth, robust on homophilous graphs |\n",
    "| **GAT** | Attention-weighted average | $\\alpha_{ij}=\\mathrm{softmax}(e_{ij})$ | $L$-hop neighbors | Adaptive, handles heterophily or noise |\n",
    "\n",
    "**Bias–variance intuition**  \n",
    "- **GCN:** stronger bias (smoothing), more stable on regular structures.  \n",
    "- **GAT:** lower bias, learns relevance of each edge dynamically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e627a7-d889-4483-8158-1363d4c90092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Compare All Models\n",
    "# ============================================================\n",
    "comparison.print_comparison()\n",
    "comparison.plot_comparison()\n",
    "comparison.plot_f1_curves()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL EXPERIMENTS COMPLETED!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de113fdb-ff09-4656-b44b-ec026f3d824e",
   "metadata": {},
   "source": [
    "# 5) Mathematical Intuition Hierarchy\n",
    "\n",
    "**Functional perspective**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{MLP:} &\\quad f:\\mathbb{R}^{d}\\!\\to\\!\\{0,1\\}.\\\\[4pt]\n",
    "\\text{GCN:} &\\quad f(G,\\mathbf{X})\\ \\text{via isotropic Laplacian smoothing.}\\\\[4pt]\n",
    "\\text{GAT:} &\\quad f(G,\\mathbf{X},\\Theta_{\\text{att}})\\ \\text{via anisotropic, data-driven attention.}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Spectral interpretation**\n",
    "$$\n",
    "\\text{GCN}\\ \\approx\\ \\text{low-pass filter on the graph Laplacian.}\n",
    "\\qquad\n",
    "\\text{GAT: replaces fixed spectral weights with learned, local attention.}\n",
    "$$\n",
    "\n",
    "**Receptive field.**  \n",
    "After $L$ layers, each node embedding incorporates information up to $L$-hop neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b6bda-7f3b-4d4c-bca9-129d91a0973a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
